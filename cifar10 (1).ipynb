{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_train = '/home/mkellylo/CIFAR-10-images-master/train/'\n",
    "raw_data_test  = '/home/mkellylo/CIFAR-10-images-master/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = []\n",
    "labels_train  = []\n",
    "targets_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse\n",
      "dog\n",
      "truck\n",
      "automobile\n",
      "ship\n",
      "airplane\n",
      "frog\n",
      "bird\n",
      "cat\n",
      "deer\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(raw_data_train):\n",
    "    print(folder)\n",
    "    ## print( os.path.join(raw_data_train, folder) )\n",
    "    for image in os.listdir( os.path.join(raw_data_train, folder) ):\n",
    "        ## print(image)\n",
    "        if folder not in labels_train:\n",
    "            labels_train.append(folder)\n",
    "        targets_train.append( labels_train.index(folder) )\n",
    "        \n",
    "        img_arr = imageio.imread( os.path.join(raw_data_train, folder, image), pilmode=\"RGB\")\n",
    "        ## resize = torchvision.transforms.Resize(size)\n",
    "        ## crop_center = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "        img = torch.from_numpy(img_arr).permute(2, 0, 1).float()\n",
    "        ## img = resize(img)\n",
    "        ## img = crop_center(img)\n",
    "        img /= 255\n",
    "        dataset_train.append(img)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( targets_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train    = torch.stack(  dataset_train )\n",
    "targets_train = torch.Tensor( targets_train ).type( torch.LongTensor )\n",
    "\n",
    "torch.save( (data_train, targets_train, labels_train) , \"CIFAR_train_dataset\")\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(dataset_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train[24000:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8353, 0.8039, 0.7882,  ..., 0.3294, 0.2980, 0.2471],\n",
       "         [0.8078, 0.8392, 0.8745,  ..., 0.3059, 0.2784, 0.2431],\n",
       "         [0.8235, 0.8431, 0.8549,  ..., 0.2824, 0.2627, 0.2549],\n",
       "         ...,\n",
       "         [0.4353, 0.4941, 0.4706,  ..., 0.3647, 0.3608, 0.3882],\n",
       "         [0.3843, 0.4196, 0.4314,  ..., 0.2980, 0.2902, 0.3529],\n",
       "         [0.4196, 0.4039, 0.4118,  ..., 0.2863, 0.2392, 0.3020]],\n",
       "\n",
       "        [[0.8078, 0.7765, 0.7529,  ..., 0.2706, 0.2471, 0.1961],\n",
       "         [0.7725, 0.8039, 0.8353,  ..., 0.2471, 0.2275, 0.1922],\n",
       "         [0.7843, 0.8039, 0.8039,  ..., 0.2157, 0.2039, 0.1961],\n",
       "         ...,\n",
       "         [0.3373, 0.3961, 0.3725,  ..., 0.3020, 0.2980, 0.3216],\n",
       "         [0.2902, 0.3255, 0.3333,  ..., 0.2471, 0.2353, 0.2980],\n",
       "         [0.3373, 0.3176, 0.3255,  ..., 0.2431, 0.1922, 0.2549]],\n",
       "\n",
       "        [[0.7765, 0.7451, 0.7176,  ..., 0.1961, 0.1725, 0.1294],\n",
       "         [0.7373, 0.7686, 0.8000,  ..., 0.1647, 0.1529, 0.1176],\n",
       "         [0.7451, 0.7647, 0.7686,  ..., 0.1373, 0.1216, 0.1137],\n",
       "         ...,\n",
       "         [0.1137, 0.1725, 0.1529,  ..., 0.1686, 0.1686, 0.2039],\n",
       "         [0.0549, 0.0902, 0.1098,  ..., 0.1216, 0.1294, 0.1922],\n",
       "         [0.0902, 0.0824, 0.0980,  ..., 0.1255, 0.0902, 0.1608]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tr = data_train[46000]\n",
    "img_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transform( img_tr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x2AF6C10BA7F0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np = targets_train.numpy() \n",
    "y_train_np.shape\n",
    "\n",
    "the_set = np.unique(  y_train_np  )\n",
    "the_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist( targets_train.numpy(), bins=\"auto\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = []\n",
    "labels_test  = []\n",
    "targets_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(raw_data_test):\n",
    "    for image in os.listdir(os.path.join(raw_data_test, folder)):\n",
    "        if folder not in labels_test:\n",
    "            labels_test.append(folder)\n",
    "        targets_test.append(labels_test.index(folder))\n",
    "        \n",
    "        img_arr = imageio.imread(os.path.join(raw_data_test, folder, image), pilmode=\"RGB\")\n",
    "        \n",
    "        img = torch.from_numpy(img_arr).permute(2, 0, 1).float()\n",
    "        img /= 255\n",
    "        \n",
    "        dataset_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.stack(dataset_test)\n",
    "targets_test = torch.Tensor(targets_test).type(torch.LongTensor)\n",
    "\n",
    "torch.save((data_test, targets_test, labels_test), \"InClass_CIFAR10_data_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10001])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist( targets_test.numpy(), bins=\"auto\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train\n",
    "y_train = targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test\n",
    "y_test = targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[30000].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0863, 0.0824, 0.0824,  ..., 0.0980, 0.0157, 0.0157],\n",
       "         [0.0784, 0.0824, 0.0745,  ..., 0.3137, 0.2039, 0.1059],\n",
       "         [0.0706, 0.0706, 0.0667,  ..., 0.6157, 0.3922, 0.1490],\n",
       "         ...,\n",
       "         [0.1176, 0.1294, 0.1294,  ..., 0.1686, 0.2000, 0.1529],\n",
       "         [0.1373, 0.1373, 0.1490,  ..., 0.1412, 0.2235, 0.1804],\n",
       "         [0.1373, 0.1373, 0.1451,  ..., 0.1765, 0.2157, 0.1490]],\n",
       "\n",
       "        [[0.4588, 0.4627, 0.4667,  ..., 0.4784, 0.4588, 0.4941],\n",
       "         [0.4588, 0.4627, 0.4706,  ..., 0.6039, 0.5490, 0.4784],\n",
       "         [0.4510, 0.4549, 0.4627,  ..., 0.7804, 0.6000, 0.3765],\n",
       "         ...,\n",
       "         [0.1137, 0.1176, 0.1176,  ..., 0.1294, 0.1608, 0.1137],\n",
       "         [0.1216, 0.1216, 0.1216,  ..., 0.0863, 0.1686, 0.1255],\n",
       "         [0.1137, 0.1137, 0.1137,  ..., 0.1176, 0.1529, 0.0863]],\n",
       "\n",
       "        [[0.6314, 0.6392, 0.6510,  ..., 0.6941, 0.6941, 0.7412],\n",
       "         [0.6275, 0.6392, 0.6510,  ..., 0.7490, 0.7059, 0.6510],\n",
       "         [0.6196, 0.6314, 0.6431,  ..., 0.8353, 0.6706, 0.4549],\n",
       "         ...,\n",
       "         [0.0941, 0.0980, 0.0980,  ..., 0.1255, 0.1569, 0.1098],\n",
       "         [0.0784, 0.0784, 0.0824,  ..., 0.0824, 0.1647, 0.1216],\n",
       "         [0.0588, 0.0588, 0.0627,  ..., 0.1059, 0.1529, 0.0863]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_train_list = [  ( X_train[i],  y_train[i].item() )  for i in range( X_train.shape[0]   )  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_test_list = [  ( X_test[i],  y_test[i].item() )  for i in range( X_test.shape[0]   )  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader( CIFAR_train_list, batch_size=batch_size, shuffle=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = torch.utils.data.DataLoader( CIFAR_test_list, batch_size=10000, shuffle=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 ,20)\n",
    "        self.act1    = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(20 , 10)\n",
    "        self.act2    = nn.Softmax(dim=1)\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.linear2(x)\n",
    "        y_pred       = self.act2(x)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop( N_Epochs, model, loss_fn, opt ):\n",
    "    for epoch in range(N_Epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            xb = xb.view(  (16, -1 ) )\n",
    "            \n",
    "            y_pred = model(xb)\n",
    "            \n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(epoch, \"loss=\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Epochs      = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_net()\n",
    "\n",
    "opt = torch.optim.Adam(  model.parameters(), lr=learning_rate  )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= tensor(1.9549, grad_fn=<NllLossBackward0>)\n",
      "5 loss= tensor(2.0823, grad_fn=<NllLossBackward0>)\n",
      "10 loss= tensor(2.1121, grad_fn=<NllLossBackward0>)\n",
      "15 loss= tensor(1.9090, grad_fn=<NllLossBackward0>)\n",
      "20 loss= tensor(2.1489, grad_fn=<NllLossBackward0>)\n",
      "25 loss= tensor(2.2223, grad_fn=<NllLossBackward0>)\n",
      "30 loss= tensor(2.2523, grad_fn=<NllLossBackward0>)\n",
      "35 loss= tensor(1.9209, grad_fn=<NllLossBackward0>)\n",
      "40 loss= tensor(2.0295, grad_fn=<NllLossBackward0>)\n",
      "45 loss= tensor(2.0096, grad_fn=<NllLossBackward0>)\n",
      "50 loss= tensor(2.1753, grad_fn=<NllLossBackward0>)\n",
      "55 loss= tensor(1.7957, grad_fn=<NllLossBackward0>)\n",
      "60 loss= tensor(2.1945, grad_fn=<NllLossBackward0>)\n",
      "65 loss= tensor(1.9577, grad_fn=<NllLossBackward0>)\n",
      "70 loss= tensor(1.9737, grad_fn=<NllLossBackward0>)\n",
      "75 loss= tensor(2.0275, grad_fn=<NllLossBackward0>)\n",
      "80 loss= tensor(1.9707, grad_fn=<NllLossBackward0>)\n",
      "85 loss= tensor(2.1951, grad_fn=<NllLossBackward0>)\n",
      "90 loss= tensor(1.9665, grad_fn=<NllLossBackward0>)\n",
      "95 loss= tensor(2.0746, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "training_loop( N_Epochs, model, loss_fn, opt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.05\n",
      "Confusion Matrix:\n",
      "[[135  33  21  22  38  78 166  99  49 360]\n",
      " [112  45  17  36  46 117 164 213  69 181]\n",
      " [ 90   8  66  32 146 512  33  47  41  25]\n",
      " [ 70  41  26  22  31  14 533  73  80 110]\n",
      " [ 98 140  59  32  60  64 158  71 226  92]\n",
      " [124 229  35  35  72  58 151  70 129  97]\n",
      " [ 37  10  96  54 576 149  24  16  33   5]\n",
      " [ 52  18 194 452  83  68  55  19  42  17]\n",
      " [523  48  68  30  33  49  53  36  48 112]\n",
      " [ 83  11 486 151  89  68  56  10  32  13]]\n",
      "Precision: 0.049\n",
      "Recall: 0.049\n",
      "F1-measure: 0.048\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        y_pred = model(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function(y_real, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
